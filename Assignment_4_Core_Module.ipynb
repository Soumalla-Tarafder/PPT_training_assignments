{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soumalla-Tarafder/PPT_training_assignments/blob/main/Assignment_4_Core_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "General Linear Model:\n",
        "\n",
        "1. What is the purpose of the General Linear Model (GLM)?\n",
        "2. What are the key assumptions of the General Linear Model?\n",
        "3. How do you interpret the coefficients in a GLM?\n",
        "4. What is the difference between a univariate and multivariate GLM?\n",
        "5. Explain the concept of interaction effects in a GLM.\n",
        "6. How do you handle categorical predictors in a GLM?\n",
        "7. What is the purpose of the design matrix in a GLM?\n",
        "8. How do you test the significance of predictors in a GLM?\n",
        "9. What is the difference between Type I, Type II, and Type III sums of squares in a GLM?\n",
        "10. Explain the concept of deviance in a GLM.\n",
        "\n",
        "Regression:\n",
        "\n",
        "11. What is regression analysis and what is its purpose?\n",
        "12. What is the difference between simple linear regression and multiple linear regression?\n",
        "13. How do you interpret the R-squared value in regression?\n",
        "14. What is the difference between correlation and regression?\n",
        "15. What is the difference between the coefficients and the intercept in regression?\n",
        "16. How do you handle outliers in regression analysis?\n",
        "17. What is the difference between ridge regression and ordinary least squares regression?\n",
        "18. What is heteroscedasticity in regression and how does it affect the model?\n",
        "19. How do you handle multicollinearity in regression analysis?\n",
        "20. What is polynomial regression and when is it used?\n",
        "\n",
        "Loss function:\n",
        "\n",
        "21. What is a loss function and what is its purpose in machine learning?\n",
        "22. What is the difference between a convex and non-convex loss function?\n",
        "23. What is mean squared error (MSE) and how is it calculated?\n",
        "24. What is mean absolute error (MAE) and how is it calculated?\n",
        "25. What is log loss (cross-entropy loss) and how is it calculated?\n",
        "26. How do you choose the appropriate loss function for a given problem?\n",
        "27. Explain the concept of regularization in the context of loss functions.\n",
        "28. What is Huber loss and how does it handle outliers?\n",
        "29. What is quantile loss and when is it used?\n",
        "30. What is the difference between squared loss and absolute loss?\n",
        "\n",
        "Optimizer (GD):\n",
        "\n",
        "31. What is an optimizer and what is its purpose in machine learning?\n",
        "32. What is Gradient Descent (GD) and how does it work?\n",
        "33. What are the different variations of Gradient Descent?\n",
        "34. What is the learning rate in GD and how do you choose an appropriate value?\n",
        "35. How does GD handle local optima in optimization problems?\n",
        "36. What is Stochastic Gradient Descent (SGD) and how does it differ from GD?\n",
        "37. Explain the concept of batch size in GD and its impact on training.\n",
        "38. What is the role of momentum in optimization algorithms?\n",
        "39. What is the difference between batch GD, mini-batch GD, and SGD?\n",
        "40. How does the learning rate affect the convergence of GD?\n",
        "\n",
        "Regularization:\n",
        "\n",
        "41. What is regularization and why is it used in machine learning?\n",
        "42. What is the difference between L1 and L2 regularization?\n",
        "43. Explain the concept of ridge regression and its role in regularization.\n",
        "44. What is the elastic net regularization and how does it combine L1 and L2 penalties?\n",
        "45. How does regularization help prevent overfitting in machine learning models?\n",
        "46. What is early stopping and how does it relate to regularization?\n",
        "47. Explain the concept of dropout regularization in neural networks.\n",
        "48. How do you choose the regularization parameter in a model?\n",
        "49. What\n",
        "\n",
        " is the difference between feature selection and regularization?\n",
        "50. What is the trade-off between bias and variance in regularized models?\n",
        "\n",
        "SVM:\n",
        "\n",
        "51. What is Support Vector Machines (SVM) and how does it work?\n",
        "52. How does the kernel trick work in SVM?\n",
        "53. What are support vectors in SVM and why are they important?\n",
        "54. Explain the concept of the margin in SVM and its impact on model performance.\n",
        "55. How do you handle unbalanced datasets in SVM?\n",
        "56. What is the difference between linear SVM and non-linear SVM?\n",
        "57. What is the role of C-parameter in SVM and how does it affect the decision boundary?\n",
        "58. Explain the concept of slack variables in SVM.\n",
        "59. What is the difference between hard margin and soft margin in SVM?\n",
        "60. How do you interpret the coefficients in an SVM model?\n",
        "\n",
        "Decision Trees:\n",
        "\n",
        "61. What is a decision tree and how does it work?\n",
        "62. How do you make splits in a decision tree?\n",
        "63. What are impurity measures (e.g., Gini index, entropy) and how are they used in decision trees?\n",
        "64. Explain the concept of information gain in decision trees.\n",
        "65. How do you handle missing values in decision trees?\n",
        "66. What is pruning in decision trees and why is it important?\n",
        "67. What is the difference between a classification tree and a regression tree?\n",
        "68. How do you interpret the decision boundaries in a decision tree?\n",
        "69. What is the role of feature importance in decision trees?\n",
        "70. What are ensemble techniques and how are they related to decision trees?\n",
        "\n",
        "Ensemble Techniques:\n",
        "\n",
        "71. What are ensemble techniques in machine learning?\n",
        "72. What is bagging and how is it used in ensemble learning?\n",
        "73. Explain the concept of bootstrapping in bagging.\n",
        "74. What is boosting and how does it work?\n",
        "75. What is the difference between AdaBoost and Gradient Boosting?\n",
        "76. What is the purpose of random forests in ensemble learning?\n",
        "77. How do random forests handle feature importance?\n",
        "78. What is stacking in ensemble learning and how does it work?\n",
        "79. What are the advantages and disadvantages of ensemble techniques?\n",
        "80. How do you choose the optimal number of models in an ensemble?\n"
      ],
      "metadata": {
        "id": "PZScDfeP9Y3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "20. A polynomial regression model is a machine learning model that can capture non-linear relationships between variables by fitting a\n",
        "non-linear regression line, which may not be possible with simple linear regression. It is used when linear regression models may not adequately capture the complexity of the relationship."
      ],
      "metadata": {
        "id": "Z2pEOEnrQ_DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "19. we need to select the feauture which are not co related to each other or we can use pca kind of featureextraction techniques\n",
        "to create the new data."
      ],
      "metadata": {
        "id": "5gzdUv5KQ-40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "18.Heteroskedasticity refers to situations where the variance of the residuals is unequal over a range of measured values.\n",
        "When running a regression analysis, heteroskedasticity results in an unequal scatter of the residuals (also known as the error term)."
      ],
      "metadata": {
        "id": "FO7cYhk6Q-uX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "16. many ways are there\n",
        "1. drop the entire row\n",
        "2. impute with mean median and mode\n",
        "3. develop another algorithm to find the missing values."
      ],
      "metadata": {
        "id": "yn0P0sBPQ-p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "15.The regression constant (b0) is equal to y-intercept the linear regression. The regression coefficient (b1) is the slope of the regression line which is equal to the average change in the dependent variable (Y) for a unit change in the independent variable (X)."
      ],
      "metadata": {
        "id": "jbGTIf0FQ-lF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "14.correlation measures the degree of a relationship between two independent variables (x and y). In contrast, regression is how one\n",
        "variable affects another."
      ],
      "metadata": {
        "id": "ZKNjLOUDQ-hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13.rsquare is used to find out the accuracy of our model this is calculated using 1-(rss/tss) formula."
      ],
      "metadata": {
        "id": "tZn4yx4WQ-eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12.in simple linear regression the no of independent feature is 1 and in multi linear regression the no of independent feature is more than one."
      ],
      "metadata": {
        "id": "g1DZS9QRQ-XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11. when the target value is continuous variable at that point we user regression analysis to predict the target value."
      ],
      "metadata": {
        "id": "oSV3J5UlPgZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "21. loss function is used calculate the loss of any algorithm and based on that model tries to improve the parameters and reduce the\n",
        "losses of trainimng"
      ],
      "metadata": {
        "id": "_hsIF5jvPgWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "23.Mean squared loss is the squared difference between the actual and the predicted value..it is prone to outliers."
      ],
      "metadata": {
        "id": "aemQUMmFPgTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "24. Mean absolute error is calculated using the actual value of the predicted and the actual value"
      ],
      "metadata": {
        "id": "MLeTke3VPgPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "25. Binary cross entropy, also referred to as logarithmic loss or log loss, is a metric used to evaluate models by measuring the extent\n",
        "of incorrect labeling of data classes."
      ],
      "metadata": {
        "id": "CfwKEqrhPgLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "30. square loss is the squared difference between the actual and the predicted value..it is prone to outliers.\n",
        "absolute error is calculated using the actual value of the predicted and the actual value"
      ],
      "metadata": {
        "id": "1yuku_cKLrZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "31. optimizer is used to optimize the loss by changes the values og the parameter used to build the equation."
      ],
      "metadata": {
        "id": "nrKkoK7BLrOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "33. some varient of gd are- sgd-mini batch sgd,sgd with momentum etc."
      ],
      "metadata": {
        "id": "SOjZvqh-LrKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "34.Lr defines that how much reduce or increase in the parameters to reduce the loss.chossing lr is a hyperparameter and it ranges from 0.01 to 0.1"
      ],
      "metadata": {
        "id": "0Tcr-vZnLrHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "35. Multiple local minima can cause to slow convergence and if we have multiple local minima then we use sub gradient to solve this problem."
      ],
      "metadata": {
        "id": "S6ZSvqyLLrDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "36.in Gd we provide the whole datapints together and the loss is less\n",
        "in sgd if feed one datapoint at a time and the loass is high"
      ],
      "metadata": {
        "id": "4OkfxHA9H3d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "39. in Gd we provide the whole datapints together and the loss is less\n",
        "in sgd if feed one datapoint at a time and the loass is high\n",
        "in minibatch gd we create a batch size and batch by batch we feed the data to the model and loss is not so low and not so high"
      ],
      "metadata": {
        "id": "gTnaBkfnH3Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "40. if we select a high lr then the gradient runs our from here to there and a small lr will ensure a smooth convergence"
      ],
      "metadata": {
        "id": "YU51OoPAH3WL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "41.Regularization refers to techniques that are used to calibrate machine learning models in order to minimize the adjusted loss\n",
        "function and prevent overfitting or underfitting. Using Regularization, we can fit our machine learning model appropriately on a\n",
        "given test set and hence reduce the errors in it."
      ],
      "metadata": {
        "id": "6sVT5vEKH3R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "42.L1 Regularization, also called a lasso regression, adds the “absolute value of magnitude” of the coefficient as a penalty term\n",
        "to the loss function. L2 Regularization, also called a ridge regression, adds the “squared magnitude” of the coefficient as the penalty\n",
        "term to the loss function.l1 Regularization also helps in feature selection."
      ],
      "metadata": {
        "id": "t8Q0zLbBH3Or"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "43.ridge regression is also l2 regularization it is adding the (magnitude)**2 with the loass function to reduce the overfitting"
      ],
      "metadata": {
        "id": "cR5SbeXuH3LK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "45. regularization addes some penalty term with the loss function to stop the loss function exact 0."
      ],
      "metadata": {
        "id": "K-86xtCJH3Hb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "46. early stopping is a concept used in nn to reduce the overfitting ,we can set the parameter that when at the time of\n",
        " tringning there will not having a change in reducing the loss or incresing the accuracy we stop the training at that point of\n",
        " time beacause it will start overfitting"
      ],
      "metadata": {
        "id": "jqpWGDi7H3Ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "47.dropout used in nn to reduce the overfitting by droping or stopping the training of the some neurons in each layers."
      ],
      "metadata": {
        "id": "27LNYCCiFf-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "48. chossing regularization parameter is a hypermarameter."
      ],
      "metadata": {
        "id": "01UciMWrFf40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "49.feature selection means to seleting the feature from all the features to trainn the model..and regulrization is used to reduce\n",
        "the overfitting by adding the penalty term with the loss function"
      ],
      "metadata": {
        "id": "5gcDhFrbFf0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "50. bais represents the error at the time of training and variance represent the error at the time of prediction .\n",
        "a low bais and a low variance model is the best model."
      ],
      "metadata": {
        "id": "rR0e-ELRFfwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "51. svm is a supervised larning algorith is used in classification and regression problem statements .It try to draw a hyperplain\n",
        "with marginal lines for mdoing the predictions."
      ],
      "metadata": {
        "id": "xiCfef_2Ffs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "52.\n",
        "kernel trick used when the dataset is not linearnly seperable or some non linearity present and we cant create a hyperplane through\n",
        "the datapoints.kernel trick used then to increase the dimensions of the data and we are able to create the plane in between the datapoints."
      ],
      "metadata": {
        "id": "6ZFl4vniFfpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "53.\n",
        "support vectors are those vectors through which the margin will be created so the support vectors are used to create the marginal line"
      ],
      "metadata": {
        "id": "cbIgQTXPFfk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "55.\n",
        "A popular algorithm for this technique is Penalized-SVM. During training, we can use the argument class_weight='balanced' to\n",
        "penalize mistakes on the minority class by an amount proportional to how under-represented it is."
      ],
      "metadata": {
        "id": "dHSXDI3tDcGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "57.High C (cost) means the cost of misclassification is increased. This means a flexible kernel will become more squiggly to avoid\n",
        "misclassifying observations in the training set."
      ],
      "metadata": {
        "id": "mv3KzojADcDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "59. Hard marginal plain means the hyperplain clearly divide the two datapoints withour doing any error\n",
        "and soft marginal plane means model create a marginal plane by considering some error points"
      ],
      "metadata": {
        "id": "2_qTIJDrDb_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "60. the svm would find only one feature useful for separating the data, then the hyperplane would be orthogonal to that axis.\n",
        "So, you could say that the absolute size of the coefficient relative to the other ones gives an indication of how important the\n",
        "feature was for the separation."
      ],
      "metadata": {
        "id": "MeR1OelFDb8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "61.A decision tree algorithm is a machine learning algorithm that uses a decision tree to make predictions.\n",
        "It follows a tree-like model of decisions and their possible consequences. The algorithm works by recursively\n",
        "splitting the data into subsets based on the most significant feature at each node of the tree."
      ],
      "metadata": {
        "id": "4jstDE-WDb43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "64. Informating Gain is calculated to decide the root of the tree"
      ],
      "metadata": {
        "id": "vUIPgqwcCLXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "65.\n",
        "1. Using Impurter(meand,median,mode)\n",
        "2.develop another model to predict the missing values.\n",
        "3.Drop the specific row which have nan values\n",
        "4.decision tree will create another branch to which have the missing values"
      ],
      "metadata": {
        "id": "NbdCaHiwCLTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "66. Purning is used to reduced the overfitting and purning simply cut the branch of the decision tree."
      ],
      "metadata": {
        "id": "u-YTSG3yCLQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "67.The major difference between a classification tree and a regression tree is the nature of the variable to be predicted. In a regression tree, the variable is continuous rather than categorical."
      ],
      "metadata": {
        "id": "vQr8HYLSCLNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "68.Deciosion boundaries is decided by calculating the Gini impurity and Information Gain values"
      ],
      "metadata": {
        "id": "8HLgK_mjCLGv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "70. In Randomforest decision trees are used and in adaboost gboosting and xgb decision tree with one level (stumps) are used."
      ],
      "metadata": {
        "id": "Ar98EuL6_wh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "71. Ensemble techniques are used to create a strong model with the help of weak model there three types of techniques\n",
        "1. bagging\n",
        "2. boosting\n",
        "3.stacking"
      ],
      "metadata": {
        "id": "Vcw3dVEG_wXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "73. in bagging bootstraping is used to split the dataset with replacement to feed the models."
      ],
      "metadata": {
        "id": "coohMRoq_wPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "74. boosting working is that - multiple base models works sequentially and the next mopdel tries to learn the errors or faults made by the previous model"
      ],
      "metadata": {
        "id": "H1oUPSTr-eNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "76.random forest is a bagging ensemble method this is used to create a strong model using the deicsion tree or base models"
      ],
      "metadata": {
        "id": "PA5QMTqW-eJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "77. In random forest we use multiple decisition tree parallely and this model randomly divide the dataset into multiple parts and then training will happen so autometically the feature is selected"
      ],
      "metadata": {
        "id": "9RsEvaky-eGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "79.advantage we can create a strong modelwith the help of multiple weak models\n",
        "disadvantage- high chance of overfitting and take lot of time to train and less interpretable"
      ],
      "metadata": {
        "id": "X4JInC7E-d5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "80.this is a hyperparameter .we need to experiment and choose the optimal based on model accuracy."
      ],
      "metadata": {
        "id": "26DVLhKr9Z9c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}